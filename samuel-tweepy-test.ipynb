{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 46,
>>>>>>> 6ffe1ca02903e1e6d9da534781869d86c8fcdbf8
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str expected, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[1;32m      9\u001b[0m client \u001b[39m=\u001b[39m MongoClient(\u001b[39m'\u001b[39m\u001b[39mlocalhost\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m27017\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m os\u001b[39m.\u001b[39;49menviron[\u001b[39m\"\u001b[39;49m\u001b[39mGOOGLE_APPLICATION_CREDENTIALS\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mGOOGLE_APPLICATION_CREDENTIALS\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m bq_client \u001b[39m=\u001b[39m bigquery\u001b[39m.\u001b[39mClient()\n\u001b[1;32m     14\u001b[0m db \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mworldcup\n",
      "File \u001b[0;32m/usr/lib/python3.10/os.py:684\u001b[0m, in \u001b[0;36m_Environ.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__setitem__\u001b[39m(\u001b[39mself\u001b[39m, key, value):\n\u001b[1;32m    683\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencodekey(key)\n\u001b[0;32m--> 684\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencodevalue(value)\n\u001b[1;32m    685\u001b[0m     putenv(key, value)\n\u001b[1;32m    686\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data[key] \u001b[39m=\u001b[39m value\n",
      "File \u001b[0;32m/usr/lib/python3.10/os.py:756\u001b[0m, in \u001b[0;36m_createenviron.<locals>.encode\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(value):\n\u001b[1;32m    755\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 756\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mstr expected, not \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(value)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    757\u001b[0m     \u001b[39mreturn\u001b[39;00m value\u001b[39m.\u001b[39mencode(encoding, \u001b[39m'\u001b[39m\u001b[39msurrogateescape\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: str expected, not NoneType"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "# from google.cloud import bigquery\n",
    "import json\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]= os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "# bq_client = bigquery.Client()\n",
    "\n",
    "db = client.worldcup\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "tweepy_client = tweepy.Client(os.getenv('BEARER_TOKEN'), wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '#ARG OR #HRV -is:retweet'\n",
    "\n",
    "paginator = tweepy.Paginator(tweepy_client.search_recent_tweets, \n",
    "                        query=query,\n",
    "                        tweet_fields = ['author_id', 'created_at', 'source', 'lang', 'geo', 'public_metrics', 'entities', 'context_annotations', 'attachments'], \n",
    "                        media_fields = ['preview_image_url', 'media_key', 'type', 'url'],\n",
    "                        exclude=['retweets', 'replies'],\n",
    "                        expansions = ['author_id', 'attachments.media_keys'], \n",
    "                        start_time = '2022-12-13T00:00:00.000Z',\n",
    "                        end_time = '2022-12-14T00:00:00.000Z',\n",
    "                        max_results = 100\n",
    "                        )\n",
    "\n",
    "for page in paginator:\n",
    "    \n",
    "    users = {u[\"id\"]: u for u in page.includes['users']}\n",
    "    media = {m[\"media_key\"]: m for m in page.includes['media']}\n",
    "\n",
    "    for tweet in page.data:\n",
    "\n",
    "        if users[tweet.author_id]:\n",
    "            user = users[tweet.author_id]\n",
    "\n",
    "        # if media:\n",
    "        #     attachments = tweet.data['attachments']\n",
    "        #     media_keys = attachments['media_keys']\n",
    "        #     media_info = {\n",
    "        #         \"media_key\": media_keys,\n",
    "        #         \"media_type\": media[media_keys[0]].type,\n",
    "        #         \"preview_image_url\": media[media_keys[0]].preview_image_url\n",
    "        #     }\n",
    "        # else:\n",
    "        #     media_info = \"\"\n",
    "        \n",
    "        tweet_content = {\n",
    "            \"tweet_id\": tweet.id,\n",
    "            \"author\": user,\n",
    "            \"created_at\": tweet.created_at,\n",
    "            \"source\": tweet.source,\n",
    "            \"lang\": tweet.lang,\n",
    "            \"geo\": tweet.geo,\n",
    "            \"public_metrics\": tweet.public_metrics,\n",
    "            \"entites\": tweet.entities,\n",
    "            \"text\": tweet.text,\n",
    "            # \"media\": media_info\n",
    "        }\n",
    "        \n",
    "        db.testarghrv.insert_one(tweet_content)\n",
    "\n",
    "# for tweet in tweets.flatten():\n",
    "#     try:\n",
    "#         print(\"1. \",tweet.data['entities'])\n",
    "#         print(\"2. \",tweet.includes['name'])\n",
    "#         for key, value in tweet.data.items():\n",
    "#             print (key, value)\n",
    "#         # db.a.insert_one(tweet)\n",
    "#         break\n",
    "#     except ValueError as e:\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_db = db.semiFinalArgHrv.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tweet_id': 1602815573871706112, 'created_at': datetime.datetime(2022, 12, 13, 23, 59, 46)}\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "for tweet in tweets_db:\n",
    "    content = {\n",
    "        \"tweet_id\": tweet['tweet_id'],\n",
    "        \"created_at\": tweet['created_at']\n",
    "    }\n",
    "\n",
    "    print(content)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('639b4899cd5550169446703e'), 'tweet_id': 1602815553168613376, 'author': {'id': 145430422, 'name': '@aycontrerasss', 'username': 'aycontrerasss'}, 'created_at': datetime.datetime(2022, 12, 13, 23, 59, 41), 'source': 'Twitter for Android', 'lang': 'qme', 'geo': None, 'public_metrics': {'retweet_count': 11, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}, 'entities': {'urls': [{'start': 57, 'end': 80, 'url': 'https://t.co/6UnavQ9zBn', 'expanded_url': 'https://twitter.com/FMPinilla/status/1602781866330886146/photo/1', 'display_url': 'pic.twitter.com/6UnavQ9zBn', 'media_key': '3_1602781862421827584'}], 'hashtags': [{'start': 15, 'end': 21, 'tag': 'Messi'}, {'start': 22, 'end': 26, 'tag': 'ARG'}, {'start': 27, 'end': 37, 'tag': 'Argentina'}, {'start': 38, 'end': 45, 'tag': 'Messi𓃵'}, {'start': 46, 'end': 56, 'tag': 'Qatar2022'}], 'mentions': [{'start': 3, 'end': 13, 'username': 'FMPinilla', 'id': '56889715'}]}, 'text': 'RT @FMPinilla: #Messi #ARG #Argentina #Messi𓃵 #Qatar2022 https://t.co/6UnavQ9zBn'}\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets_db:\n",
    "    print(tweet)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/samuelhui/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/samuelhui/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = 'RT @FMPinilla: #Messi #ARG #Argentina #Messi𓃵 #Qatar2022 https://t.co/6UnavQ9zBn'\n",
    "token = nltk.word_tokenize(raw)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punct_set = set(string.punctuation)\n",
    "filtered_tokens = [w for w in token\n",
    "                    if not w.lower() in stop_words and \n",
    "                     not punct_set.issuperset(set(w))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT', 'FMPinilla', 'Messi', 'ARG', 'Argentina', 'Messi𓃵', 'Qatar2022', 'https', '//t.co/6UnavQ9zBn']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "None\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "d = {\"a\": {\"b\":1}}\n",
    "\n",
    "print(type(d))\n",
    "print(d[\"a\"].get(\"c\"))\n",
    "print(type(d[\"a\"].get(\"c\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Messi', 'ARG', 'UniversoMundial', 'Qatar2022', 'FIFAWorldCup']\n",
      "['(Organization) ARG', '(Other) UniversoMundial', '(Other) Qatar2022', '(Other) FIFAWorldCup']\n",
      "['Messi']\n",
      "{'hashtags': 'Messi, ARG, UniversoMundial, Qatar2022, FIFAWorldCup', 'annotations': '(Organization) ARG, (Other) UniversoMundial, (Other) Qatar2022, (Other) FIFAWorldCup', 'annotations_person': 'Messi'}\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "for tweet in tweets_db:\n",
    "    hashtags = []\n",
    "    if tweet['entities'].get('hashtags'):\n",
    "        for hashtag in tweet['entities']['hashtags']:\n",
    "            hashtags.append(hashtag['tag'])\n",
    "    print(hashtags)\n",
    "\n",
    "    annotations = []\n",
    "    annotations_person = []\n",
    "    if tweet['entities'].get('annotations'):\n",
    "        for anno in tweet['entities']['annotations']:\n",
    "            if anno['type'] == \"Person\":\n",
    "                annotations_person.append(anno['normalized_text'])\n",
    "            else:\n",
    "                annotations.append(f'({anno[\"type\"]}) {anno[\"normalized_text\"]}')\n",
    "    print(annotations)\n",
    "    print(annotations_person)\n",
    "\n",
    "    con = {\n",
    "        \"hashtags\": \", \".join(hashtags),\n",
    "        \"annotations\": \", \".join(annotations),\n",
    "        \"annotations_person\": \", \".join(annotations_person)\n",
    "    }\n",
    "    print(con)\n",
    "    # break\n",
    "    # print(tweet.text)\n",
    "    # print(tweet['created_at'].date())\n",
    "    # print(tweet['created_at'].time())\n",
    "    # print(tweet['tweet_id'])\n",
    "    # print(tweet['author']['id'])\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'_id': ObjectId('639b1b51c2728b12d0639cd1'), \n",
    " 'tweet_id': 1602815590644830210, \n",
    " 'author': {'id': 138911752, \n",
    "            'name': 'ricardo leon crespo', \n",
    "            'username': 'tatuleonc'}, \n",
    " 'created_at': datetime.datetime(2022, 12, 13, 23, 59, 50), \n",
    " 'source': 'Twitter for Android', \n",
    " 'lang': 'es', \n",
    " 'geo': None, \n",
    " 'public_metrics': {'retweet_count': 154, \n",
    "                    'reply_count': 0, \n",
    "                    'like_count': 0, \n",
    "                    'quote_count': 0}, \n",
    " 'entites': {'mentions': [{'start': 3, \n",
    "                           'end': 12, \n",
    "                           'username': 'Jwillocv', \n",
    "                           'id': '1552259230547296256'}], \n",
    "             'annotations': [{'start': 59, \n",
    "                              'end': 63, \n",
    "                              'probability': 0.9821, \n",
    "                              'type': 'Person', \n",
    "                              'normalized_text': 'Messi'}, \n",
    "                             {'start': 67, \n",
    "                              'end': 72, \n",
    "                              'probability': 0.968, \n",
    "                              'type': 'Person', \n",
    "                              'normalized_text': 'Armani'}, \n",
    "                            {'start': 79, \n",
    "                             'end': 81, \n",
    "                             'probability': 0.9358, \n",
    "                             'type': 'Organization', \n",
    "                             'normalized_text': 'ARG'}, \n",
    "                            {'start': 84, 'end': 97, \n",
    "                             'probability': 0.5483, \n",
    "                             'type': 'Organization', \n",
    "                             'normalized_text': 'VamosArgentina'}, \n",
    "                            {'start': 100, 'end': 111, \n",
    "                             'probability': 0.8338, \n",
    "                             'type': 'Other', \n",
    "                             'normalized_text': 'FIFAWorldCup'}, \n",
    "                            {'start': 114, 'end': 122, \n",
    "                             'probability': 0.8587, \n",
    "                             'type': 'Other', \n",
    "                             'normalized_text': 'Qatar2022'}], \n",
    "             'hashtags': [{'start': 78, 'end': 82, 'tag': 'ARG'}, \n",
    "                          {'start': 83, 'end': 98, 'tag': 'VamosArgentina'}, \n",
    "                          {'start': 99, 'end': 112, 'tag': 'FIFAWorldCup'}, \n",
    "                          {'start': 113, 'end': 123, 'tag': 'Qatar2022'}]}, \n",
    " 'text': 'RT @Jwillocv: Hermosooooooooooooooos 😍😍😍😍\\n\\nEl abrazo entre Messi y Armani 💙🤍💙\\n#ARG #VamosArgentina #FIFAWorldCup #Qatar2022 https://t.co/Kp…'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-13\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "a = datetime.datetime(2022, 12, 13, 23, 59, 57)\n",
    "print (a.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpn_vs_hrv = bq_client.get_table('tecky-capstone-project.worldcup.jpn_hrv')\n",
    "\n",
    "x = db.jh.find()\n",
    "for row in x:\n",
    "    row['_id'] = str(row['_id'])\n",
    "    row['Date_Created'] = str(row['Date_Created'])\n",
    "    bq_client.insert_rows_json(jpn_vs_hrv,[row])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c41cc7a6bf458ae2af5583a7906ef5f402c759b4882f3cbfc8ede19b81b2d2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
