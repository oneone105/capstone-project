{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "# from google.cloud import bigquery\n",
    "import json\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]= os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "# bq_client = bigquery.Client()\n",
    "\n",
    "db = client.worldcup\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "tweepy_client = tweepy.Client(os.getenv('BEARER_TOKEN'), wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '#ARG OR #HRV -is:retweet'\n",
    "\n",
    "paginator = tweepy.Paginator(tweepy_client.search_recent_tweets, \n",
    "                        query=query,\n",
    "                        tweet_fields = ['author_id', 'created_at', 'source', 'lang', 'geo', 'public_metrics', 'entities', 'context_annotations', 'attachments'], \n",
    "                        media_fields = ['preview_image_url', 'media_key', 'type', 'url'],\n",
    "                        exclude=['retweets', 'replies'],\n",
    "                        expansions = ['author_id', 'attachments.media_keys'], \n",
    "                        start_time = '2022-12-13T00:00:00.000Z',\n",
    "                        end_time = '2022-12-14T00:00:00.000Z',\n",
    "                        max_results = 100\n",
    "                        )\n",
    "\n",
    "for page in paginator:\n",
    "    \n",
    "    users = {u[\"id\"]: u for u in page.includes['users']}\n",
    "    media = {m[\"media_key\"]: m for m in page.includes['media']}\n",
    "\n",
    "    for tweet in page.data:\n",
    "\n",
    "        if users[tweet.author_id]:\n",
    "            user = users[tweet.author_id]\n",
    "\n",
    "        # if media:\n",
    "        #     attachments = tweet.data['attachments']\n",
    "        #     media_keys = attachments['media_keys']\n",
    "        #     media_info = {\n",
    "        #         \"media_key\": media_keys,\n",
    "        #         \"media_type\": media[media_keys[0]].type,\n",
    "        #         \"preview_image_url\": media[media_keys[0]].preview_image_url\n",
    "        #     }\n",
    "        # else:\n",
    "        #     media_info = \"\"\n",
    "        \n",
    "        tweet_content = {\n",
    "            \"tweet_id\": tweet.id,\n",
    "            \"author\": user,\n",
    "            \"created_at\": tweet.created_at,\n",
    "            \"source\": tweet.source,\n",
    "            \"lang\": tweet.lang,\n",
    "            \"geo\": tweet.geo,\n",
    "            \"public_metrics\": tweet.public_metrics,\n",
    "            \"entites\": tweet.entities,\n",
    "            \"text\": tweet.text,\n",
    "            # \"media\": media_info\n",
    "        }\n",
    "        \n",
    "        db.testarghrv.insert_one(tweet_content)\n",
    "\n",
    "# for tweet in tweets.flatten():\n",
    "#     try:\n",
    "#         print(\"1. \",tweet.data['entities'])\n",
    "#         print(\"2. \",tweet.includes['name'])\n",
    "#         for key, value in tweet.data.items():\n",
    "#             print (key, value)\n",
    "#         # db.a.insert_one(tweet)\n",
    "#         break\n",
    "#     except ValueError as e:\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_db = db.semiFinalArgHrv.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "for tweet in tweets_db:\n",
    "    content = {\n",
    "        \"tweet_id\": tweet['tweet_id'],\n",
    "        \"created_at\": tweet['created_at']\n",
    "    }\n",
    "\n",
    "    print(content)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweets_db:\n",
    "    print(tweet)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = 'RT @FMPinilla: #Messi #ARG #Argentina #MessiìÉµ #Qatar2022 https://t.co/6UnavQ9zBn'\n",
    "token = nltk.word_tokenize(raw)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punct_set = set(string.punctuation)\n",
    "filtered_tokens = [w for w in token\n",
    "                    if not w.lower() in stop_words and \n",
    "                     not punct_set.issuperset(set(w))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"a\": {\"b\":1}}\n",
    "\n",
    "print(type(d))\n",
    "print(d[\"a\"].get(\"c\"))\n",
    "print(type(d[\"a\"].get(\"c\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "for tweet in tweets_db:\n",
    "    hashtags = []\n",
    "    if tweet['entities'].get('hashtags'):\n",
    "        for hashtag in tweet['entities']['hashtags']:\n",
    "            hashtags.append(hashtag['tag'])\n",
    "    print(hashtags)\n",
    "\n",
    "    annotations = []\n",
    "    annotations_person = []\n",
    "    if tweet['entities'].get('annotations'):\n",
    "        for anno in tweet['entities']['annotations']:\n",
    "            if anno['type'] == \"Person\":\n",
    "                annotations_person.append(anno['normalized_text'])\n",
    "            else:\n",
    "                annotations.append(f'({anno[\"type\"]}) {anno[\"normalized_text\"]}')\n",
    "    print(annotations)\n",
    "    print(annotations_person)\n",
    "\n",
    "    con = {\n",
    "        \"hashtags\": \", \".join(hashtags),\n",
    "        \"annotations\": \", \".join(annotations),\n",
    "        \"annotations_person\": \", \".join(annotations_person)\n",
    "    }\n",
    "    print(con)\n",
    "    # break\n",
    "    # print(tweet.text)\n",
    "    # print(tweet['created_at'].date())\n",
    "    # print(tweet['created_at'].time())\n",
    "    # print(tweet['tweet_id'])\n",
    "    # print(tweet['author']['id'])\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'_id': ObjectId('639b1b51c2728b12d0639cd1'), \n",
    " 'tweet_id': 1602815590644830210, \n",
    " 'author': {'id': 138911752, \n",
    "            'name': 'ricardo leon crespo', \n",
    "            'username': 'tatuleonc'}, \n",
    " 'created_at': datetime.datetime(2022, 12, 13, 23, 59, 50), \n",
    " 'source': 'Twitter for Android', \n",
    " 'lang': 'es', \n",
    " 'geo': None, \n",
    " 'public_metrics': {'retweet_count': 154, \n",
    "                    'reply_count': 0, \n",
    "                    'like_count': 0, \n",
    "                    'quote_count': 0}, \n",
    " 'entites': {'mentions': [{'start': 3, \n",
    "                           'end': 12, \n",
    "                           'username': 'Jwillocv', \n",
    "                           'id': '1552259230547296256'}], \n",
    "             'annotations': [{'start': 59, \n",
    "                              'end': 63, \n",
    "                              'probability': 0.9821, \n",
    "                              'type': 'Person', \n",
    "                              'normalized_text': 'Messi'}, \n",
    "                             {'start': 67, \n",
    "                              'end': 72, \n",
    "                              'probability': 0.968, \n",
    "                              'type': 'Person', \n",
    "                              'normalized_text': 'Armani'}, \n",
    "                            {'start': 79, \n",
    "                             'end': 81, \n",
    "                             'probability': 0.9358, \n",
    "                             'type': 'Organization', \n",
    "                             'normalized_text': 'ARG'}, \n",
    "                            {'start': 84, 'end': 97, \n",
    "                             'probability': 0.5483, \n",
    "                             'type': 'Organization', \n",
    "                             'normalized_text': 'VamosArgentina'}, \n",
    "                            {'start': 100, 'end': 111, \n",
    "                             'probability': 0.8338, \n",
    "                             'type': 'Other', \n",
    "                             'normalized_text': 'FIFAWorldCup'}, \n",
    "                            {'start': 114, 'end': 122, \n",
    "                             'probability': 0.8587, \n",
    "                             'type': 'Other', \n",
    "                             'normalized_text': 'Qatar2022'}], \n",
    "             'hashtags': [{'start': 78, 'end': 82, 'tag': 'ARG'}, \n",
    "                          {'start': 83, 'end': 98, 'tag': 'VamosArgentina'}, \n",
    "                          {'start': 99, 'end': 112, 'tag': 'FIFAWorldCup'}, \n",
    "                          {'start': 113, 'end': 123, 'tag': 'Qatar2022'}]}, \n",
    " 'text': 'RT @Jwillocv: Hermosooooooooooooooos üòçüòçüòçüòç\\n\\nEl abrazo entre Messi y Armani üíôü§çüíô\\n#ARG #VamosArgentina #FIFAWorldCup #Qatar2022 https://t.co/Kp‚Ä¶'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "a = datetime.datetime(2022, 12, 13, 23, 59, 57)\n",
    "print (a.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpn_vs_hrv = bq_client.get_table('tecky-capstone-project.worldcup.jpn_hrv')\n",
    "\n",
    "x = db.jh.find()\n",
    "for row in x:\n",
    "    row['_id'] = str(row['_id'])\n",
    "    row['Date_Created'] = str(row['Date_Created'])\n",
    "    bq_client.insert_rows_json(jpn_vs_hrv,[row])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c41cc7a6bf458ae2af5583a7906ef5f402c759b4882f3cbfc8ede19b81b2d2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
